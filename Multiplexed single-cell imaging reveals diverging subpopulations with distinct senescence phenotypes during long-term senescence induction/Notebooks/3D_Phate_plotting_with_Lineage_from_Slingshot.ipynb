{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8162ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import phate\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "import scprep\n",
    "from datetime import datetime, time\n",
    "from matplotlib.animation import ImageMagickWriter\n",
    "import matplotlib.animation as animation\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import kde\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.stats import f_oneway\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "print(sns.__version__)\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "from delve import *\n",
    "import anndata as ad\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from kh import sketch\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "print(sc.__version__)\n",
    "today = datetime.now().strftime(\"%m%d%Y-%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read back in the subsampled adata file\n",
    "adata_save_path = r'your/file/path/here.h5ad'\n",
    "standard_trimmed_noPSTAT5_adata_sub = anndata.read_h5ad(adata_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359db9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_score_fs(adata = None,\n",
    "                    k: int  = None,\n",
    "                    n_jobs: int  = -1):\n",
    "\n",
    "    X, feature_names, obs_names = parse_input(adata)\n",
    "    W = construct_affinity(X = X, k = k, n_jobs = n_jobs)\n",
    "    scores = laplacian_score(X = X, W = W)\n",
    "    predicted_features = pd.DataFrame(scores, index = feature_names, columns = ['laplacian_score'])\n",
    "    predicted_features = predicted_features.sort_values(by = 'laplacian_score', ascending = True)\n",
    "\n",
    "    return predicted_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d643e0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_score_standard = laplacian_score_fs(standard_trimmed_noPSTAT5_noTotal_adata_sub, k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a925de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(l_score_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed07509",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_score_standard.index[:46]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05702d63",
   "metadata": {},
   "source": [
    "Code below taking inputs from Slingshot processing (Done in R) and any provided Clustering strategy.\n",
    "Phate must be run and the PHATE coordinates saved using methods from the PHATE plotting notebook.\n",
    "Produces a graph that plots specified clusters and overlays the Lineage information provided by Slingshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4603b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "\n",
    "# Step 1: Retrieve the PHATE embeddings from the AnnData object\n",
    "embedding = standard_trimmed_noPSTAT5_adata_sub.obsm['X_phate']\n",
    "\n",
    "# Gather all unique sample IDs to ensure they are represented in the final table\n",
    "all_sample_ids = standard_trimmed_noPSTAT5_adata_sub.obs['sample_ID'].unique()\n",
    "\n",
    "# Define a list of K values to loop through\n",
    "k_values = [10]\n",
    "\n",
    "# Specify the order of the clusters you want to plot\n",
    "clusters_to_plot = [3, 8, 0, 4, 7]\n",
    "\n",
    "# Specify the order of the columns to be plotted on the table\n",
    "columns_to_plot = ['Cluster 3', 'Cluster 8', 'Cluster 0', 'Cluster 4', 'Cluster 7']\n",
    "\n",
    "# Load CSV data\n",
    "csv_path = r'your/trajectories/here.csv'\n",
    "lineage_data = pd.read_csv(csv_path)  # Changed variable name to lineage_data\n",
    "\n",
    "# Identify unique lineages and assign a color to each\n",
    "unique_lineages = lineage_data['Lineage'].unique()\n",
    "lineage_color_map = plt.get_cmap('tab10', len(unique_lineages))\n",
    "lineage_colors = lineage_color_map(np.linspace(0, 1, len(unique_lineages)))\n",
    "lineage_color_dict = dict(zip(unique_lineages, lineage_colors))\n",
    "\n",
    "for k in k_values:\n",
    "    # Run K-means clustering for the current value of K using the precomputed PHATE embeddings\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(embedding)\n",
    "    \n",
    "    # Assign the cluster labels back to the AnnData object\n",
    "    cluster_label = f'kmeans_clusters_k{k}'\n",
    "    standard_trimmed_noPSTAT5_adata_sub.obs[cluster_label] = kmeans.labels_.astype(str)\n",
    "    \n",
    "    # Plotting the clusters\n",
    "    views = [(30, 30), (30, 120), (30, 210), (30, 300)]\n",
    "    \n",
    "    for i, (elev, azim) in enumerate(views, start=1):\n",
    "        # Create a 3D subplot for points with white background\n",
    "        fig_points = plt.figure(figsize=(20, 16))\n",
    "        ax_points = fig_points.add_subplot(1, 1, 1, projection='3d', facecolor='white')\n",
    "        cluster_handles = []\n",
    "        for cluster in clusters_to_plot:\n",
    "            mask = kmeans.labels_ == cluster\n",
    "            scatter = ax_points.scatter(embedding[mask, 0], embedding[mask, 1], embedding[mask, 2], label=f'Cluster {cluster}', s=50, zorder=1)\n",
    "            cluster_handles.append(scatter)\n",
    "        \n",
    "        ax_points.scatter(embedding[:, 0], embedding[:, 1], embedding[:, 2], c='gray', alpha=0.3, s=5, zorder=0)\n",
    "        ax_points.view_init(elev=elev, azim=azim)\n",
    "        ax_points.set_xlabel('PHATE 1')\n",
    "        ax_points.set_ylabel('PHATE 2')\n",
    "        ax_points.set_zlabel('PHATE 3')\n",
    "        ax_points.set_title(f'View {i} - Elev {elev}, Azim {azim}')\n",
    "        ax_points.set_facecolor('white')  # Set the background color to white\n",
    "\n",
    "        # Capture the axis limits\n",
    "        xlim = ax_points.get_xlim()\n",
    "        ylim = ax_points.get_ylim()\n",
    "        zlim = ax_points.get_zlim()\n",
    "        \n",
    "        fig_points.savefig(f'points_view_{i}.png', transparent=True)\n",
    "        plt.close(fig_points)\n",
    "        \n",
    "        # Create a 3D subplot for lines with the same axis limits and transparent background\n",
    "        fig_lines = plt.figure(figsize=(20, 16))\n",
    "        ax_lines = fig_lines.add_subplot(1, 1, 1, projection='3d')\n",
    "        fig_lines.patch.set_alpha(0)  # Set the figure background to be transparent\n",
    "        ax_lines.patch.set_alpha(0)  # Set the axes background to be transparent\n",
    "        ax_lines.axis('off')  # Remove the axis\n",
    "        lineage_handles = []\n",
    "        for lineage, lineage_color in lineage_color_dict.items():\n",
    "            lineage_subset = lineage_data[lineage_data['Lineage'] == lineage].sort_values('Index')\n",
    "            # Apply cutoff for Lineage 2\n",
    "            if (lineage == 2) and ('Index' in lineage_subset.columns):\n",
    "                lineage_subset = lineage_subset[lineage_subset['Index'] <= 70]\n",
    "            line, = ax_lines.plot(lineage_subset['PHATE_1'], lineage_subset['PHATE_2'], lineage_subset['PHATE_3'], \n",
    "                                  color=lineage_color, label=f'Lineage {lineage}', linewidth=2, zorder=2)\n",
    "            lineage_handles.append(line)\n",
    "        \n",
    "        ax_lines.view_init(elev=elev, azim=azim)\n",
    "        ax_lines.set_xlim(xlim)\n",
    "        ax_lines.set_ylim(ylim)\n",
    "        ax_lines.set_zlim(zlim)\n",
    "        # Remove axis labels and titles\n",
    "        ax_lines.set_xlabel('')\n",
    "        ax_lines.set_ylabel('')\n",
    "        ax_lines.set_zlabel('')\n",
    "        ax_lines.set_title('')\n",
    "        fig_lines.savefig(f'lines_view_{i}.png', transparent=True)\n",
    "        plt.close(fig_lines)\n",
    "        \n",
    "        # Combine images\n",
    "        points_image = Image.open(f'points_view_{i}.png')\n",
    "        lines_image = Image.open(f'lines_view_{i}.png')\n",
    "        combined_image = Image.alpha_composite(points_image.convert('RGBA'), lines_image.convert('RGBA'))\n",
    "        combined_image.save(f'combined_view_{i}.png')\n",
    "        \n",
    "        # Save the legend as a separate image\n",
    "        fig_legend = plt.figure(figsize=(10, 5))\n",
    "        ax_legend = fig_legend.add_subplot(111)\n",
    "        ax_legend.axis('off')  # Hide the axes for the legend\n",
    "        legend_handles = cluster_handles + lineage_handles\n",
    "        legend_labels = [handle.get_label() for handle in legend_handles]\n",
    "        legend = ax_legend.legend(handles=legend_handles, labels=legend_labels, loc='center', frameon=False)\n",
    "        fig_legend.savefig(f'legend_view_{i}.png', transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close(fig_legend)\n",
    "    \n",
    "    # Creating the table\n",
    "    cluster_sample_table = pd.DataFrame(0, index=all_sample_ids, columns=[f'Cluster {i}' for i in range(k)])\n",
    "    for i in range(k):\n",
    "        cluster_counts = standard_trimmed_noPSTAT5_adata_sub.obs[standard_trimmed_noPSTAT5_adata_sub.obs[cluster_label] == str(i)].groupby('sample_ID').size()\n",
    "        cluster_sample_table.loc[cluster_counts.index, f'Cluster {i}'] = cluster_counts\n",
    "\n",
    "    # Calculate percentages row-wise\n",
    "    cluster_sample_table_percentage = cluster_sample_table.div(cluster_sample_table.sum(axis=1), axis=0) * 100\n",
    "\n",
    "    # Filter the table to include only the specified columns\n",
    "    cluster_sample_table_filtered = cluster_sample_table_percentage[columns_to_plot]\n",
    "\n",
    "    # Plotting the table as a heatmap\n",
    "    plt.figure(figsize=(5, 6))\n",
    "    sns.heatmap(cluster_sample_table_filtered, annot=True, cmap=\"YlGnBu\", fmt=\".1f\", linewidths=.5)\n",
    "    plt.title(f'Percentage of Each Sample IDâ€™s Total Cells in Each Cluster for K={k}')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Sample ID')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
